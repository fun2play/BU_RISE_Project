{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39fff169",
   "metadata": {},
   "source": [
    "### STE Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f764578c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mne\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from HFODetector import ste\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f19845ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = Path('../hfo/ds003555/derivatives/')\n",
    "edf_files = sorted(data_root.rglob(\"*.edf\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee994e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14415757",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# edf = mne.io.read_raw_edf('../data/ds004100/')\n",
    "# header = ','.join(edf.ch_names)\n",
    "# np.savetxt('test1.csv', edf.get_data().T, delimiter=',', header=header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb5b3892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: sub-01_ses-01_task-hfo_run-01_eeg.edf\n",
      "Extracting EDF parameters from /Users/billhuang/Desktop/BU_RISE/BU_RISE_Project/hfo/ds003555/derivatives/sub-01/ses-01/eeg/sub-01_ses-01_task-hfo_run-01_eeg.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51.0/51.0 [00:05<00:00, 9.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: sub-01_ses-01_task-hfo_run-02_eeg.edf\n",
      "Extracting EDF parameters from /Users/billhuang/Desktop/BU_RISE/BU_RISE_Project/hfo/ds003555/derivatives/sub-01/ses-01/eeg/sub-01_ses-01_task-hfo_run-02_eeg.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 51.0/51.0 [00:05<00:00, 10.0it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: sub-01_ses-01_task-hfo_run-03_eeg.edf\n",
      "Extracting EDF parameters from /Users/billhuang/Desktop/BU_RISE/BU_RISE_Project/hfo/ds003555/derivatives/sub-01/ses-01/eeg/sub-01_ses-01_task-hfo_run-03_eeg.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 32\u001b[39m\n\u001b[32m     29\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m     31\u001b[39m \u001b[38;5;66;03m# Run HFO detection\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m channel_names, start_end = detector.detect_edf(\u001b[38;5;28mstr\u001b[39m(edf_path))\n\u001b[32m     34\u001b[39m \u001b[38;5;66;03m# Filter by good channels\u001b[39;00m\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m ch, intervals \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(channel_names, start_end):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/mbta_env/lib/python3.13/site-packages/HFODetector/ste.py:80\u001b[39m, in \u001b[36mSTEDetector.detect_edf\u001b[39m\u001b[34m(self, edf_path)\u001b[39m\n\u001b[32m     67\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"detect HFOs from an EDF file\u001b[39;00m\n\u001b[32m     68\u001b[39m \u001b[33;03m\u001b[39;00m\n\u001b[32m     69\u001b[39m \u001b[33;03mParameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     76\u001b[39m \u001b[33;03mchannel_names : numpy array of str, shape (n_channels,)\u001b[39;00m\n\u001b[32m     77\u001b[39m \u001b[33;03mHFOs : numpy array of int, shape (n_channels, n_HFOs, 2)\"\"\"\u001b[39;00m\n\u001b[32m     79\u001b[39m edf_path = validate_type(edf_path, \u001b[33m'\u001b[39m\u001b[33medf_path\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28mstr\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m80\u001b[39m raw, channels = read_raw(edf_path)\n\u001b[32m     81\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.detect_multi_channels(data=raw, channels=channels)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/mbta_env/lib/python3.13/site-packages/HFODetector/utils.py:79\u001b[39m, in \u001b[36mread_raw\u001b[39m\u001b[34m(raw_path)\u001b[39m\n\u001b[32m     76\u001b[39m data = []\n\u001b[32m     78\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m raw_ch \u001b[38;5;129;01min\u001b[39;00m raw_channels:\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m     ch_data = raw.get_data(raw_ch) * \u001b[32m1E6\u001b[39m\n\u001b[32m     80\u001b[39m     data.append(ch_data)\n\u001b[32m     82\u001b[39m data = np.squeeze(data)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<decorator-gen-192>:12\u001b[39m, in \u001b[36mget_data\u001b[39m\u001b[34m(self, picks, start, stop, reject_by_annotation, return_times, units, tmin, tmax, verbose)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/mbta_env/lib/python3.13/site-packages/mne/io/base.py:977\u001b[39m, in \u001b[36mBaseRaw.get_data\u001b[39m\u001b[34m(self, picks, start, stop, reject_by_annotation, return_times, units, tmin, tmax, verbose)\u001b[39m\n\u001b[32m    974\u001b[39m stop = \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mmax\u001b[39m(\u001b[32m0\u001b[39m, stop), \u001b[38;5;28mself\u001b[39m.n_times)\n\u001b[32m    976\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.annotations) == \u001b[32m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m reject_by_annotation \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m977\u001b[39m     getitem = \u001b[38;5;28mself\u001b[39m._getitem(\n\u001b[32m    978\u001b[39m         (picks, \u001b[38;5;28mslice\u001b[39m(start, stop)), return_times=return_times\n\u001b[32m    979\u001b[39m     )\n\u001b[32m    980\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m return_times:\n\u001b[32m    981\u001b[39m         data, times = getitem\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/mbta_env/lib/python3.13/site-packages/mne/io/base.py:874\u001b[39m, in \u001b[36mBaseRaw._getitem\u001b[39m\u001b[34m(self, item, return_times)\u001b[39m\n\u001b[32m    872\u001b[39m     data = \u001b[38;5;28mself\u001b[39m._data[sel, start:stop]\n\u001b[32m    873\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m874\u001b[39m     data = \u001b[38;5;28mself\u001b[39m._read_segment(start=start, stop=stop, sel=sel)\n\u001b[32m    876\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m return_times:\n\u001b[32m    877\u001b[39m     \u001b[38;5;66;03m# Rather than compute the entire thing just compute the subset\u001b[39;00m\n\u001b[32m    878\u001b[39m     \u001b[38;5;66;03m# times = self.times[start:stop]\u001b[39;00m\n\u001b[32m    879\u001b[39m     \u001b[38;5;66;03m# stop can be None here so don't use it directly\u001b[39;00m\n\u001b[32m    880\u001b[39m     times = np.arange(start, start + data.shape[\u001b[32m1\u001b[39m], dtype=\u001b[38;5;28mfloat\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<decorator-gen-189>:12\u001b[39m, in \u001b[36m_read_segment\u001b[39m\u001b[34m(self, start, stop, sel, data_buffer, verbose)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/mbta_env/lib/python3.13/site-packages/mne/io/base.py:477\u001b[39m, in \u001b[36mBaseRaw._read_segment\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    475\u001b[39m     \u001b[38;5;66;03m# reindex back to original file\u001b[39;00m\n\u001b[32m    476\u001b[39m     orig_idx = _convert_slice(\u001b[38;5;28mself\u001b[39m._read_picks[fi][need_idx])\n\u001b[32m--> \u001b[39m\u001b[32m477\u001b[39m     _ReadSegmentFileProtector(\u001b[38;5;28mself\u001b[39m)._read_segment_file(\n\u001b[32m    478\u001b[39m         data[:, this_sl],\n\u001b[32m    479\u001b[39m         orig_idx,\n\u001b[32m    480\u001b[39m         fi,\n\u001b[32m    481\u001b[39m         \u001b[38;5;28mint\u001b[39m(start_file),\n\u001b[32m    482\u001b[39m         \u001b[38;5;28mint\u001b[39m(stop_file),\n\u001b[32m    483\u001b[39m         cals,\n\u001b[32m    484\u001b[39m         mult,\n\u001b[32m    485\u001b[39m     )\n\u001b[32m    486\u001b[39m     offset += n_read\n\u001b[32m    487\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/mbta_env/lib/python3.13/site-packages/mne/io/base.py:2704\u001b[39m, in \u001b[36m_ReadSegmentFileProtector._read_segment_file\u001b[39m\u001b[34m(self, data, idx, fi, start, stop, cals, mult)\u001b[39m\n\u001b[32m   2703\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_read_segment_file\u001b[39m(\u001b[38;5;28mself\u001b[39m, data, idx, fi, start, stop, cals, mult):\n\u001b[32m-> \u001b[39m\u001b[32m2704\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.__raw.\u001b[34m__class__\u001b[39m._read_segment_file(\n\u001b[32m   2705\u001b[39m         \u001b[38;5;28mself\u001b[39m, data, idx, fi, start, stop, cals, mult\n\u001b[32m   2706\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/mbta_env/lib/python3.13/site-packages/mne/io/edf/edf.py:221\u001b[39m, in \u001b[36mRawEDF._read_segment_file\u001b[39m\u001b[34m(self, data, idx, fi, start, stop, cals, mult)\u001b[39m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_read_segment_file\u001b[39m(\u001b[38;5;28mself\u001b[39m, data, idx, fi, start, stop, cals, mult):\n\u001b[32m    220\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Read a chunk of raw data.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m221\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _read_segment_file(\n\u001b[32m    222\u001b[39m         data,\n\u001b[32m    223\u001b[39m         idx,\n\u001b[32m    224\u001b[39m         fi,\n\u001b[32m    225\u001b[39m         start,\n\u001b[32m    226\u001b[39m         stop,\n\u001b[32m    227\u001b[39m         \u001b[38;5;28mself\u001b[39m._raw_extras[fi],\n\u001b[32m    228\u001b[39m         \u001b[38;5;28mself\u001b[39m.filenames[fi],\n\u001b[32m    229\u001b[39m         cals,\n\u001b[32m    230\u001b[39m         mult,\n\u001b[32m    231\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/mbta_env/lib/python3.13/site-packages/mne/io/edf/edf.py:399\u001b[39m, in \u001b[36m_read_segment_file\u001b[39m\u001b[34m(data, idx, fi, start, stop, raw_extras, filenames, cals, mult)\u001b[39m\n\u001b[32m    397\u001b[39m fid.seek(start_offset + block_offset, \u001b[32m0\u001b[39m)\n\u001b[32m    398\u001b[39m \u001b[38;5;66;03m# Read and reshape to (n_chunks_read, ch0_ch1_ch2_ch3...)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m399\u001b[39m many_chunk = _read_ch(\n\u001b[32m    400\u001b[39m     fid, subtype, ch_offsets[-\u001b[32m1\u001b[39m] * n_read, dtype_byte, dtype\n\u001b[32m    401\u001b[39m ).reshape(n_read, -\u001b[32m1\u001b[39m)\n\u001b[32m    402\u001b[39m r_sidx = r_lims[ai][\u001b[32m0\u001b[39m]\n\u001b[32m    403\u001b[39m r_eidx = buf_len * (n_read - \u001b[32m1\u001b[39m) + r_lims[ai + n_read - \u001b[32m1\u001b[39m][\u001b[32m1\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/mbta_env/lib/python3.13/site-packages/mne/io/edf/edf.py:348\u001b[39m, in \u001b[36m_read_ch\u001b[39m\u001b[34m(fid, subtype, samp, dtype_byte, dtype)\u001b[39m\n\u001b[32m    344\u001b[39m     ch_data[ch_data >= (\u001b[32m1\u001b[39m << \u001b[32m23\u001b[39m)] -= \u001b[32m1\u001b[39m << \u001b[32m24\u001b[39m\n\u001b[32m    346\u001b[39m \u001b[38;5;66;03m# GDF data and EDF data\u001b[39;00m\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m348\u001b[39m     ch_data = np.fromfile(fid, dtype=dtype, count=samp)\n\u001b[32m    350\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m ch_data\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# edf_path = '../data/ds\n",
    "detector = ste.STEDetector(\n",
    "    # filter paramters\n",
    "    sample_freq=2000.0,  # changed from 500 to 2000\n",
    "    filter_freq=[80, 200],\n",
    "    # STE parameters\n",
    "    rms_window=3*1e-3, \n",
    "    min_window=6*1e-3, \n",
    "    min_gap=10 * 1e-3, \n",
    "    epoch_len=600, \n",
    "    min_osc=6, \n",
    "    rms_thres=5, \n",
    "    peak_thres=3,\n",
    "    # multi-processing parameters\n",
    "    n_jobs=4, #Caution: this depends on how many core you CPU has\n",
    "    front_num=1\n",
    ")\n",
    "\n",
    "results = []\n",
    "\n",
    "for edf_path in edf_files:\n",
    "    try:\n",
    "        print(f\"Processing: {edf_path.name}\")\n",
    "        \n",
    "        # Locate matching channels.tsv\n",
    "        channels_path = edf_path.with_name(edf_path.name.replace(\"_ieeg.edf\", \"_channels.tsv\"))\n",
    "        if not channels_path.exists():\n",
    "            print(f\"Missing channel file: {channels_path.name}\")\n",
    "            continue\n",
    "\n",
    "        # Run HFO detection\n",
    "        channel_names, start_end = detector.detect_edf(str(edf_path))\n",
    "\n",
    "        # Filter by good channels\n",
    "        for ch, intervals in zip(channel_names, start_end):\n",
    "            hfo_count = len(intervals)\n",
    "            hfo_duration = sum(e - s for s, e in intervals)\n",
    "            results.append({\n",
    "                \"file\": edf_path.name,\n",
    "                \"channel\": ch,\n",
    "                \"n_hfos\": hfo_count,\n",
    "                \"duration_samples\": hfo_duration,  # divide by 500.0 for seconds if needed\n",
    "                \"duration_sec\": hfo_duration / 500.0\n",
    "            })\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error with {edf_path.name}: {e}\")\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(\"../hfo/hfo_detection_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a36b2b1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>channel</th>\n",
       "      <th>n_hfos</th>\n",
       "      <th>duration_samples</th>\n",
       "      <th>duration_sec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sub-01_ses-01_task-hfo_run-01_eeg.edf</td>\n",
       "      <td>Fp1-Fp2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sub-01_ses-01_task-hfo_run-01_eeg.edf</td>\n",
       "      <td>Fp1-F7</td>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>0.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sub-01_ses-01_task-hfo_run-01_eeg.edf</td>\n",
       "      <td>F7-T3</td>\n",
       "      <td>3</td>\n",
       "      <td>279</td>\n",
       "      <td>0.558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sub-01_ses-01_task-hfo_run-01_eeg.edf</td>\n",
       "      <td>T3-T5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sub-01_ses-01_task-hfo_run-01_eeg.edf</td>\n",
       "      <td>T5-O1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    file  channel  n_hfos  duration_samples  \\\n",
       "0  sub-01_ses-01_task-hfo_run-01_eeg.edf  Fp1-Fp2       0                 0   \n",
       "1  sub-01_ses-01_task-hfo_run-01_eeg.edf   Fp1-F7       2               200   \n",
       "2  sub-01_ses-01_task-hfo_run-01_eeg.edf    F7-T3       3               279   \n",
       "3  sub-01_ses-01_task-hfo_run-01_eeg.edf    T3-T5       0                 0   \n",
       "4  sub-01_ses-01_task-hfo_run-01_eeg.edf    T5-O1       0                 0   \n",
       "\n",
       "   duration_sec  \n",
       "0         0.000  \n",
       "1         0.400  \n",
       "2         0.558  \n",
       "3         0.000  \n",
       "4         0.000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69b702c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to remove bad channels and use only ictal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62341d9",
   "metadata": {},
   "source": [
    "### MNI Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09d8a3f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59 59\n"
     ]
    }
   ],
   "source": [
    "# channel_names is a list that is the same length as the number of channels in the edf\n",
    "# start_end is a nested list with the same length as channel_names. start_end[i][j][0] and start_end[i][j][1] \n",
    "# will give the start and end index respectively for the jth detected HFO in channel \n",
    "print(len(channel_names), len(start_end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3adfe0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to pandas dataframe\n",
    "channel_names = np.concatenate([[channel_names[i]]*len(start_end[i]) for i in range(len(channel_names))])\n",
    "#removes channels that have no HFO detections\n",
    "start_end = [start_end[i] for i in range(len(start_end)) if len(start_end[i])>0]\n",
    "#combines all detected start-end time intervals into one big list\n",
    "start_end = np.concatenate(start_end)\n",
    "\n",
    "#Creates a table (DataFrame) with three columns:\n",
    "# \"channel\": channel name where the HFO was detected.\n",
    "#\"start\": start time (or sample index) of the detected HFO.\n",
    "#\"end\": end time (or sample index) of the detected HFO.\n",
    "HFO_ste_df = pd.DataFrame({\"channel\":channel_names,\"start\":start_end[:,0],\"end\":start_end[:,1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "317951b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channel</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C3</td>\n",
       "      <td>91126</td>\n",
       "      <td>91156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C3</td>\n",
       "      <td>91452</td>\n",
       "      <td>91465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C3</td>\n",
       "      <td>97340</td>\n",
       "      <td>97354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C4</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C4</td>\n",
       "      <td>188898</td>\n",
       "      <td>188937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CZ</td>\n",
       "      <td>188907</td>\n",
       "      <td>188932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>EKG1</td>\n",
       "      <td>86905</td>\n",
       "      <td>86931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>EKG1</td>\n",
       "      <td>88386</td>\n",
       "      <td>88411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>EKG2</td>\n",
       "      <td>86921</td>\n",
       "      <td>86942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>EKG2</td>\n",
       "      <td>88387</td>\n",
       "      <td>88404</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  channel   start     end\n",
       "0      C3   91126   91156\n",
       "1      C3   91452   91465\n",
       "2      C3   97340   97354\n",
       "3      C4       0      19\n",
       "4      C4  188898  188937\n",
       "5      CZ  188907  188932\n",
       "6    EKG1   86905   86931\n",
       "7    EKG1   88386   88411\n",
       "8    EKG2   86921   86942\n",
       "9    EKG2   88387   88404"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HFO_ste_df.head(10)\n",
    "#channel = which EEG channel detected the HFO\n",
    "#start = when it started\n",
    "#end = when it ended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fea2f055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  channel   start     end\n",
      "0      C3   91126   91156\n",
      "1      C3   91452   91465\n",
      "2      C3   97340   97354\n",
      "3      C4       0      19\n",
      "4      C4  188898  188937\n"
     ]
    }
   ],
   "source": [
    "HFO_ste_df.to_csv(\"HFO_ste.csv\", index=False)\n",
    "print(HFO_ste_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90d3542",
   "metadata": {},
   "source": [
    "MNI Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6406d671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from C:\\Users\\washi\\OneDrive\\Documents\\Final Project\\sub-HUP060\\ses-presurgery\\ieeg\\sub-HUP060_ses-presurgery_task-ictal_acq-seeg_run-01_ieeg.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 58.0/58.0 [01:31<00:00, 1.58s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "edf_path = 'C:\\\\Users\\\\washi\\\\OneDrive\\\\Documents\\\\Final Project\\\\sub-HUP060\\\\ses-presurgery\\\\ieeg\\\\sub-HUP060_ses-presurgery_task-ictal_acq-seeg_run-01_ieeg.edf' #change this to your edf path\n",
    "sample_freq=2000 #change this to your sample frequency\n",
    "detector = mni.MNIDetector(sample_freq, filter_freq=[80, 500], \n",
    "            epoch_time=10, epo_CHF=60, per_CHF=95/100, \n",
    "            min_win=10*1e-3, min_gap=10*1e-3, thrd_perc=99.9999/100, \n",
    "            base_seg=125*1e-3, base_shift=0.5, base_thrd=0.67, base_min=5,\n",
    "            n_jobs=32, front_num=1)\n",
    "channel_names, start_end = detector.detect_edf(edf_path)\n",
    "channel_names = np.concatenate([[channel_names[i]]*len(start_end[i]) for i in range(len(channel_names))])\n",
    "start_end = [start_end[i] for i in range(len(start_end)) if len(start_end[i])>0]\n",
    "start_end = np.concatenate(start_end)\n",
    "HFO_mni_df = pd.DataFrame({\"channel\":channel_names,\"start\":start_end[:,0],\"end\":start_end[:,1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f352324a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  channel   start     end\n",
      "0      C3       0      32\n",
      "1      C3  181625  189000\n",
      "2      C4       0      43\n",
      "3      C4  177875  189000\n",
      "4      CZ       0      56\n"
     ]
    }
   ],
   "source": [
    "HFO_mni_df.head(10)\n",
    "HFO_mni_df.to_csv(\"HFO_mni.csv\", index=False)\n",
    "print(HFO_mni_df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mbta_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
